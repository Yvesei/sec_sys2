# ğŸš€ Quick Start - Jenkins Security Dataset avec ELK Stack

## Installation en 5 minutes

### 1. PrÃ©parer l'environnement
```bash
# CrÃ©er le dossier du projet
mkdir jenkins-security-dataset
cd jenkins-security-dataset

# CrÃ©er les dossiers nÃ©cessaires
mkdir -p scripts attack_scripts dataset/{logs,output}

# TÃ©lÃ©charger les fichiers de configuration :
# - docker-compose.yml
# - jenkins-logging.properties
# - filebeat.yml
```

### 2. DÃ©marrer l'infrastructure ELK + Jenkins
```bash
# DÃ©marrer tous les services
docker-compose up -d

# VÃ©rifier que tout est dÃ©marrÃ©
docker-compose ps

# Vous devriez voir :
# - elasticsearch (port 9200)
# - kibana (port 5601)
# - jenkins (port 8080)
# - filebeat (collecteur)
```

### 3. VÃ©rifier que les services sont prÃªts
```bash
# VÃ©rifier Elasticsearch
curl http://localhost:9200/_cluster/health

# VÃ©rifier Kibana (attendre 1-2 minutes)
curl http://localhost:5601/api/status

# VÃ©rifier Jenkins (attendre 2-3 minutes)
curl http://localhost:8080
```

### 4. Configuration initiale de Jenkins
```bash
# Obtenir le mot de passe admin initial
docker exec jenkins cat /var/jenkins_home/secrets/initialAdminPassword

# AccÃ©der Ã  Jenkins : http://localhost:8080
# - Coller le mot de passe
# - Installer les plugins recommandÃ©s
# - CrÃ©er un compte admin (username: admin, password: admin)
```

### 5. VÃ©rifier la collecte des logs dans Kibana

#### AccÃ©der Ã  Kibana
```
URL: http://localhost:5601
```

#### CrÃ©er un Index Pattern
1. Menu (â˜°) â†’ **Stack Management** â†’ **Index Patterns**
2. Cliquer sur **Create index pattern**
3. Index pattern name : `filebeat-*`
4. Time field : `@timestamp`
5. Cliquer sur **Create index pattern**

#### Visualiser les logs Jenkins
1. Menu (â˜°) â†’ **Discover**
2. SÃ©lectionner l'index pattern `filebeat-*`
3. Vous devriez voir les logs Jenkins en temps rÃ©el

#### Filtrer uniquement Jenkins
Dans la barre de recherche KQL :
```kql
container.name: "jenkins"
```

### 6. VÃ©rifier les logs FINEST
Dans Kibana Discover, rechercher :
```kql
container.name: "jenkins" AND log.level: "FINEST"
```

Vous devriez voir des logs trÃ¨s dÃ©taillÃ©s comme :
```
FINEST hudson.model.Queue maintain
FINEST jenkins.model.Jenkins getQueue
```

**Si vous ne voyez pas de logs FINEST**, redÃ©marrer Jenkins :
```bash
docker-compose restart jenkins
# Attendre 2 minutes puis vÃ©rifier Ã  nouveau
```

### 7. Collecter le dataset complet

#### Option A : Collecte automatique (RECOMMANDÃ‰E)
```bash
# Lance tout automatiquement :
# - 1h de trafic normal (10 users)
# - Toutes les attaques
# - Export et transformation MITRE CAR
python3 scripts/collect_dataset.py \
  --jenkins-url http://localhost:8080 \
  --normal-duration 3600 \
  --normal-users 10 \
  --backend elasticsearch

# Dataset final : dataset/output/jenkins-logs-mitre-car.json
```

#### Option B : Collecte manuelle Ã©tape par Ã©tape
```bash
# 1. Trafic normal (1 heure)
python3 scripts/generate_normal_traffic.py \
  --target http://localhost:8080 \
  --users 10 \
  --duration 3600

# 2. Attaques (aprÃ¨s le trafic normal)
python3 attack_scripts/brute_force.py \
  --target http://localhost:8080 \
  --duration 300

sleep 60

python3 attack_scripts/xxe_injection.py \
  --target http://localhost:8080 \
  --user admin \
  --password admin \
  --duration 300

sleep 60

python3 attack_scripts/rce_script_console.py \
  --target http://localhost:8080 \
  --user admin \
  --password admin \
  --attack-type all

# 3. Export depuis Elasticsearch
curl -X GET "localhost:9200/filebeat-*/_search?size=10000&pretty" \
  -H 'Content-Type: application/json' \
  -d '{
    "query": {
      "bool": {
        "must": [
          { "match": { "container.name": "jenkins" } }
        ]
      }
    },
    "sort": [{ "@timestamp": "asc" }]
  }' > dataset/logs/jenkins-logs-raw.json

# 4. Transformer en MITRE CAR
python3 scripts/transform_to_mitre_car.py \
  --input dataset/logs/jenkins-logs-raw.json \
  --output dataset/output/jenkins-logs-mitre-car.json \
  --annotate
```

## ğŸ“Š RequÃªtes Kibana utiles

### Discover - Barre de recherche KQL

**Tous les logs Jenkins :**
```kql
container.name: "jenkins"
```

**Authentifications Ã©chouÃ©es (Brute Force) :**
```kql
container.name: "jenkins" AND message: "authentication failed"
```

**Script Console (RCE) :**
```kql
container.name: "jenkins" AND (message: "script console" OR message: "groovy")
```

**Tentatives XXE :**
```kql
container.name: "jenkins" AND (message: "<!ENTITY" OR message: "<!DOCTYPE" OR message: "SYSTEM")
```

**Logs de niveau WARNING ou SEVERE :**
```kql
container.name: "jenkins" AND (log.level: "WARNING" OR log.level: "SEVERE")
```

**Timeline horaire des logs :**
```kql
container.name: "jenkins"
```
Puis ajuster l'intervalle de temps en haut Ã  droite (par ex. Last 1 hour)

## ğŸ¨ CrÃ©er des visualisations dans Kibana

### 1. Dashboard d'attaques

**Menu â†’ Dashboard â†’ Create dashboard â†’ Create visualization**

#### Graphique 1 : Tentatives d'authentification dans le temps
- Type : **Line**
- Metrics : Count
- Buckets : 
  - X-axis : Date Histogram sur `@timestamp`
  - Split series : Filters
    - Filter 1: `message: "authentication failed"` (label: Failed)
    - Filter 2: `message: "authentication success"` (label: Success)

#### Graphique 2 : Top des types d'Ã©vÃ©nements
- Type : **Pie**
- Metrics : Count
- Buckets : Split slices sur `log.level`

#### Graphique 3 : ActivitÃ© Script Console
- Type : **Metric**
- Metrics : Count
- Add filter : `message: "script console"`

### 2. Sauvegarder le dashboard
- Cliquer sur **Save**
- Nom : "Jenkins Security Monitoring"

## ğŸ›¡ï¸ CrÃ©er des rÃ¨gles de dÃ©tection

### Menu â†’ Security â†’ Rules â†’ Detection rules â†’ Create new rule

#### RÃ¨gle 1 : Brute Force Detection
```
Rule type: Custom query
Index pattern: filebeat-*

Query:
container.name: "jenkins" AND message: "authentication failed"

Conditions:
- When number of matches is above 10
- In a 5 minute window

Actions:
- Send email / webhook / etc.
```

#### RÃ¨gle 2 : Script Console Access
```
Rule type: Custom query
Index pattern: filebeat-*

Query:
container.name: "jenkins" AND (message: "script console" OR message: "groovy")

Conditions:
- When query returns at least 1 result

Severity: High
```

#### RÃ¨gle 3 : XXE Injection Attempt
```
Rule type: Custom query
Index pattern: filebeat-*

Query:
container.name: "jenkins" AND (message: "<!ENTITY" OR message: "<!DOCTYPE")

Conditions:
- When query returns at least 1 result

Severity: Critical
```

## ğŸ› DÃ©pannage

### Les logs n'apparaissent pas dans Kibana

**1. VÃ©rifier que Filebeat collecte les logs**
```bash
# Voir les logs de Filebeat
docker logs filebeat

# Vous devriez voir des lignes comme :
# "Harvester started for file"
# "Non-zero metrics in the last 30s"
```

**2. VÃ©rifier qu'Elasticsearch reÃ§oit les donnÃ©es**
```bash
# Lister les indices
curl http://localhost:9200/_cat/indices?v

# Vous devriez voir des indices filebeat-*
```

**3. VÃ©rifier que Jenkins produit bien des logs FINEST**
```bash
# Voir les logs Jenkins
docker logs jenkins 2>&1 | grep FINEST | head -20

# Si vous ne voyez pas FINEST, vÃ©rifier la config
docker exec jenkins cat /var/jenkins_home/logging.properties
```

### Jenkins ne dÃ©marre pas
```bash
docker logs jenkins
docker-compose restart jenkins
```

### Elasticsearch est lent ou plante
```bash
# VÃ©rifier la mÃ©moire allouÃ©e dans docker-compose.yml
# ES_JAVA_OPTS doit Ãªtre : -Xms2g -Xmx2g minimum

# Augmenter si nÃ©cessaire et redÃ©marrer
docker-compose down
docker-compose up -d
```

### RecrÃ©er l'index pattern
```bash
# Si l'index pattern ne fonctionne pas
# Dans Kibana :
# Stack Management â†’ Index Patterns â†’ Supprimer filebeat-*
# Puis recrÃ©er avec les Ã©tapes ci-dessus
```

## ğŸ“ Structure des donnÃ©es dans Elasticsearch

Les logs Jenkins sont stockÃ©s avec cette structure :
```json
{
  "@timestamp": "2024-02-11T10:15:23.000Z",
  "container": {
    "name": "jenkins",
    "id": "abc123..."
  },
  "message": "FINEST hudson.model.Queue maintain",
  "log": {
    "level": "FINEST"
  },
  "stream": "stdout"
}
```

## ğŸ“š Prochaines Ã©tapes

1. âœ… VÃ©rifier les logs dans Kibana
2. âœ… CrÃ©er des dashboards
3. âœ… Configurer les rÃ¨gles de dÃ©tection
4. âœ… Collecter le dataset avec les scripts Python
5. âœ… Transformer au format MITRE CAR
6. âœ… Analyser et documenter les rÃ©sultats

## ğŸ¯ Points de vÃ©rification

- [ ] Elasticsearch rÃ©pond sur http://localhost:9200
- [ ] Kibana accessible sur http://localhost:5601
- [ ] Jenkins accessible sur http://localhost:8080
- [ ] Index pattern `filebeat-*` crÃ©Ã© dans Kibana
- [ ] Logs Jenkins visibles dans Discover
- [ ] Logs au niveau FINEST prÃ©sents
- [ ] Scripts Python fonctionnels

---

**Votre infrastructure ELK + Jenkins est prÃªte ! ğŸš€**

Pour plus de dÃ©tails, consulter **README.md**
